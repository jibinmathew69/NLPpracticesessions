{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    reviewsFile = open('reviews.txt','r')\n",
    "    reviews = list(map(lambda x:x[:-1],reviewsFile.readlines()))\n",
    "    reviewsFile.close()\n",
    "\n",
    "    labelsFile = open('labels.txt','r')\n",
    "    labels = list(map(lambda x:x[:-1],labelsFile.readlines()))\n",
    "    labelsFile.close()\n",
    "    \n",
    "    return reviews,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews,labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(\"\\w+\\'?\\w+|\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptionStopWords = {\n",
    "    'again',\n",
    "    'against',\n",
    "    'ain',\n",
    "    'almost',\n",
    "    'among',\n",
    "    'amongst',\n",
    "    'amount',\n",
    "    'anyhow',\n",
    "    'anyway',\n",
    "    'aren',\n",
    "    \"aren't\",\n",
    "    'below',\n",
    "    'bottom',\n",
    "    'but',\n",
    "    'cannot',\n",
    "    'couldn',\n",
    "    \"couldn't\",\n",
    "    'didn',\n",
    "    \"didn't\",\n",
    "    'doesn',\n",
    "    \"doesn't\",\n",
    "    'don',\n",
    "    \"don't\",\n",
    "    'done',\n",
    "    'down',\n",
    "    'except',\n",
    "    'few',\n",
    "    'hadn',\n",
    "    \"hadn't\",\n",
    "    'hasn',\n",
    "    \"hasn't\",\n",
    "    'haven',\n",
    "    \"haven't\",\n",
    "    'however',\n",
    "    'isn',\n",
    "    \"isn't\",\n",
    "    'least',\n",
    "    'mightn',\n",
    "    \"mightn't\",\n",
    "    'move',\n",
    "    'much',\n",
    "    'must',\n",
    "    'mustn',\n",
    "    \"mustn't\",\n",
    "    'needn',\n",
    "    \"needn't\",\n",
    "    'neither',\n",
    "    'never',\n",
    "    'nevertheless',\n",
    "    'no',\n",
    "    'nobody',\n",
    "    'none',\n",
    "    'noone',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'nothing',\n",
    "    'should',\n",
    "    \"should've\",\n",
    "    'shouldn',\n",
    "    \"shouldn't\",\n",
    "    'too',\n",
    "    'top',\n",
    "    'up',\n",
    "    'wasn',\n",
    "    \"wasn't\",\n",
    "    'well',\n",
    "    'weren',\n",
    "    \"weren't\",\n",
    "    'won',\n",
    "    \"won't\",\n",
    "    'wouldn',\n",
    "    \"wouldn't\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words).union(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stop_words = stop_words-exceptionStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\",disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token(review):\n",
    "    return tokenizer.tokenize(str(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(review):\n",
    "    return [token for token in review if token not in final_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(review):\n",
    "    lemma_result = []\n",
    "    \n",
    "    for words in review:\n",
    "        doc = nlp(words)\n",
    "        for token in doc:\n",
    "            lemma_result.append(token.lemma_)\n",
    "    return lemma_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(review):\n",
    "    review = make_token(review)\n",
    "    review = remove_stopwords(review)\n",
    "    return lemmatization(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.9 s, sys: 62.8 ms, total: 36 s\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews = list(map(lambda review: pipeline(review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = Word2Vec(reviews,size=100, min_count=3, window=5, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bromwell',\n",
       "  'high',\n",
       "  'cartoon',\n",
       "  'comedy',\n",
       "  'run',\n",
       "  'time',\n",
       "  'program',\n",
       "  'school',\n",
       "  'life',\n",
       "  'teacher',\n",
       "  'year',\n",
       "  'teach',\n",
       "  'profession',\n",
       "  'lead',\n",
       "  'believe',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'satire',\n",
       "  'much',\n",
       "  'close',\n",
       "  'reality',\n",
       "  'teacher',\n",
       "  'scramble',\n",
       "  'survive',\n",
       "  'financially',\n",
       "  'insightful',\n",
       "  'student',\n",
       "  'right',\n",
       "  'pathetic',\n",
       "  'teacher',\n",
       "  'pomp',\n",
       "  'pettiness',\n",
       "  'situation',\n",
       "  'remind',\n",
       "  'school',\n",
       "  'know',\n",
       "  'student',\n",
       "  'see',\n",
       "  'episode',\n",
       "  'student',\n",
       "  'repeatedly',\n",
       "  'try',\n",
       "  'burn',\n",
       "  'down',\n",
       "  'school',\n",
       "  'immediately',\n",
       "  'recall',\n",
       "  'high',\n",
       "  'classic',\n",
       "  'line',\n",
       "  'inspector',\n",
       "  'sack',\n",
       "  'teacher',\n",
       "  'student',\n",
       "  'welcome',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'expect',\n",
       "  'adult',\n",
       "  'age',\n",
       "  'think',\n",
       "  'bromwell',\n",
       "  'high',\n",
       "  'far',\n",
       "  'fetch',\n",
       "  'pity',\n",
       "  'isn'],\n",
       " ['story',\n",
       "  'man',\n",
       "  'unnatural',\n",
       "  'feeling',\n",
       "  'pig',\n",
       "  'start',\n",
       "  'open',\n",
       "  'scene',\n",
       "  'terrific',\n",
       "  'example',\n",
       "  'absurd',\n",
       "  'comedy',\n",
       "  'formal',\n",
       "  'orchestra',\n",
       "  'audience',\n",
       "  'turn',\n",
       "  'insane',\n",
       "  'violent',\n",
       "  'mob',\n",
       "  'crazy',\n",
       "  'chantings',\n",
       "  'singer',\n",
       "  'unfortunately',\n",
       "  'stay',\n",
       "  'absurd',\n",
       "  'time',\n",
       "  'no',\n",
       "  'general',\n",
       "  'narrative',\n",
       "  'eventually',\n",
       "  'make',\n",
       "  'too',\n",
       "  'putt',\n",
       "  'era',\n",
       "  'should',\n",
       "  'turn',\n",
       "  'cryptic',\n",
       "  'dialogue',\n",
       "  'shakespeare',\n",
       "  'easy',\n",
       "  'grader',\n",
       "  'technical',\n",
       "  'level',\n",
       "  'well',\n",
       "  'think',\n",
       "  'good',\n",
       "  'cinematography',\n",
       "  'future',\n",
       "  'great',\n",
       "  'vilmos',\n",
       "  'zsigmond',\n",
       "  'future',\n",
       "  'star',\n",
       "  'sally',\n",
       "  'kirkland',\n",
       "  'frederic',\n",
       "  'forrest',\n",
       "  'see',\n",
       "  'briefly'],\n",
       " ['homelessness',\n",
       "  'houselessness',\n",
       "  'george',\n",
       "  'carlin',\n",
       "  'state',\n",
       "  'issue',\n",
       "  'year',\n",
       "  'but',\n",
       "  'never',\n",
       "  'plan',\n",
       "  'help',\n",
       "  'street',\n",
       "  'consider',\n",
       "  'human',\n",
       "  'go',\n",
       "  'school',\n",
       "  'work',\n",
       "  'vote',\n",
       "  'matt',\n",
       "  'people',\n",
       "  'think',\n",
       "  'homeless',\n",
       "  'lose',\n",
       "  'because',\n",
       "  'worry',\n",
       "  'thing',\n",
       "  'racism',\n",
       "  'war',\n",
       "  'iraq',\n",
       "  'pressure',\n",
       "  'kid',\n",
       "  'succeed',\n",
       "  'technology',\n",
       "  'election',\n",
       "  'inflation',\n",
       "  'worry',\n",
       "  'end',\n",
       "  'up',\n",
       "  'street',\n",
       "  'br',\n",
       "  'br',\n",
       "  'but',\n",
       "  'give',\n",
       "  'bet',\n",
       "  'live',\n",
       "  'street',\n",
       "  'month',\n",
       "  'luxury',\n",
       "  'home',\n",
       "  'entertainment',\n",
       "  'set',\n",
       "  'bathroom',\n",
       "  'picture',\n",
       "  'wall',\n",
       "  'computer',\n",
       "  'treasure',\n",
       "  'like',\n",
       "  'homeless',\n",
       "  'goddard',\n",
       "  'bolt',\n",
       "  'lesson',\n",
       "  'br',\n",
       "  'br',\n",
       "  'mel',\n",
       "  'brook',\n",
       "  'direct',\n",
       "  'star',\n",
       "  'bolt',\n",
       "  'play',\n",
       "  'rich',\n",
       "  'man',\n",
       "  'world',\n",
       "  'decide',\n",
       "  'bet',\n",
       "  'sissy',\n",
       "  'rival',\n",
       "  'jeffery',\n",
       "  'tambor',\n",
       "  'live',\n",
       "  'street',\n",
       "  'thirty',\n",
       "  'day',\n",
       "  'luxury',\n",
       "  'bolt',\n",
       "  'succeed',\n",
       "  'want',\n",
       "  'future',\n",
       "  'project',\n",
       "  'make',\n",
       "  'building',\n",
       "  'bet',\n",
       "  'bolt',\n",
       "  'throw',\n",
       "  'street',\n",
       "  'bracelet',\n",
       "  'leg',\n",
       "  'monitor',\n",
       "  'move',\n",
       "  'step',\n",
       "  'sidewalk',\n",
       "  'give',\n",
       "  'nickname',\n",
       "  'pepto',\n",
       "  'vagrant',\n",
       "  'write',\n",
       "  'forehead',\n",
       "  'bolt',\n",
       "  'meet',\n",
       "  'character',\n",
       "  'include',\n",
       "  'woman',\n",
       "  'molly',\n",
       "  'lesley',\n",
       "  'ann',\n",
       "  'warren',\n",
       "  'ex',\n",
       "  'dancer',\n",
       "  'get',\n",
       "  'divorce',\n",
       "  'lose',\n",
       "  'home',\n",
       "  'pal',\n",
       "  'sailor',\n",
       "  'howard',\n",
       "  'morris',\n",
       "  'fume',\n",
       "  'teddy',\n",
       "  'wilson',\n",
       "  'street',\n",
       "  'survivor',\n",
       "  'bolt',\n",
       "  'isn',\n",
       "  'not',\n",
       "  'reach',\n",
       "  'mutual',\n",
       "  'agreement',\n",
       "  'like',\n",
       "  'rich',\n",
       "  'fight',\n",
       "  'flight',\n",
       "  'kill',\n",
       "  'kill',\n",
       "  'br',\n",
       "  'br',\n",
       "  'love',\n",
       "  'connection',\n",
       "  'molly',\n",
       "  'bolt',\n",
       "  'wasn',\n",
       "  'necessary',\n",
       "  'plot',\n",
       "  'find',\n",
       "  'life',\n",
       "  'stink',\n",
       "  'mel',\n",
       "  'brook',\n",
       "  'observant',\n",
       "  'film',\n",
       "  'prior',\n",
       "  'comedy',\n",
       "  'show',\n",
       "  'tender',\n",
       "  'compare',\n",
       "  'slapstick',\n",
       "  'work',\n",
       "  'blaze',\n",
       "  'saddle',\n",
       "  'young',\n",
       "  'frankenstein',\n",
       "  'spaceballs',\n",
       "  'matt',\n",
       "  'like',\n",
       "  'valuable',\n",
       "  'lose',\n",
       "  'day',\n",
       "  'hand',\n",
       "  'make',\n",
       "  'stupid',\n",
       "  'bet',\n",
       "  'like',\n",
       "  'rich',\n",
       "  'people',\n",
       "  'don',\n",
       "  'know',\n",
       "  'money',\n",
       "  'maybe',\n",
       "  'should',\n",
       "  'homeless',\n",
       "  'instead',\n",
       "  'like',\n",
       "  'monopoly',\n",
       "  'money',\n",
       "  'br',\n",
       "  'br',\n",
       "  'maybe',\n",
       "  'film',\n",
       "  'inspire',\n",
       "  'help'],\n",
       " ['airport',\n",
       "  'start',\n",
       "  'brand',\n",
       "  'new',\n",
       "  'luxury',\n",
       "  'plane',\n",
       "  'load',\n",
       "  'up',\n",
       "  'valuable',\n",
       "  'painting',\n",
       "  'belong',\n",
       "  'rich',\n",
       "  'businessman',\n",
       "  'philip',\n",
       "  'stevens',\n",
       "  'james',\n",
       "  'stewart',\n",
       "  'fly',\n",
       "  'bunch',\n",
       "  'vip',\n",
       "  'estate',\n",
       "  'preparation',\n",
       "  'open',\n",
       "  'public',\n",
       "  'museum',\n",
       "  'board',\n",
       "  'stevens',\n",
       "  'daughter',\n",
       "  'julie',\n",
       "  'kathleen',\n",
       "  'quinlan',\n",
       "  'son',\n",
       "  'luxury',\n",
       "  'jetliner',\n",
       "  'take',\n",
       "  'plan',\n",
       "  'but',\n",
       "  'mid',\n",
       "  'air',\n",
       "  'plane',\n",
       "  'hello',\n",
       "  'jack',\n",
       "  'co',\n",
       "  'pilot',\n",
       "  'chamber',\n",
       "  'robert',\n",
       "  'foxworth',\n",
       "  'accomplice',\n",
       "  'banker',\n",
       "  'monte',\n",
       "  'markham',\n",
       "  'wilson',\n",
       "  'michael',\n",
       "  'pataki',\n",
       "  'knock',\n",
       "  'passenger',\n",
       "  'crow',\n",
       "  'sleep',\n",
       "  'gas',\n",
       "  'plan',\n",
       "  'steal',\n",
       "  'valuable',\n",
       "  'cargo',\n",
       "  'land',\n",
       "  'disused',\n",
       "  'plane',\n",
       "  'strip',\n",
       "  'isolate',\n",
       "  'island',\n",
       "  'but',\n",
       "  'make',\n",
       "  'descent',\n",
       "  'chamber',\n",
       "  'almost',\n",
       "  'hit',\n",
       "  'oil',\n",
       "  'rig',\n",
       "  'ocean',\n",
       "  'lose',\n",
       "  'control',\n",
       "  'plane',\n",
       "  'send',\n",
       "  'crash',\n",
       "  'sea',\n",
       "  'sink',\n",
       "  'bottom',\n",
       "  'right',\n",
       "  'bang',\n",
       "  'middle',\n",
       "  'bermuda',\n",
       "  'triangle',\n",
       "  'air',\n",
       "  'short',\n",
       "  'supply',\n",
       "  'water',\n",
       "  'leak',\n",
       "  'fly',\n",
       "  'mile',\n",
       "  'course',\n",
       "  'problem',\n",
       "  'mount',\n",
       "  'survivor',\n",
       "  'await',\n",
       "  'help',\n",
       "  'time',\n",
       "  'fast',\n",
       "  'run',\n",
       "  'br',\n",
       "  'br',\n",
       "  'know',\n",
       "  'slightly',\n",
       "  'different',\n",
       "  'tile',\n",
       "  'airport',\n",
       "  '2',\n",
       "  'sequel',\n",
       "  'smash',\n",
       "  'hit',\n",
       "  'disaster',\n",
       "  'thriller',\n",
       "  'airport',\n",
       "  'direct',\n",
       "  'jerry',\n",
       "  'jameson',\n",
       "  'again',\n",
       "  'like',\n",
       "  'predecessor',\n",
       "  'airport',\n",
       "  'sort',\n",
       "  'forget',\n",
       "  'classic',\n",
       "  'entertain',\n",
       "  'not',\n",
       "  'necessarily',\n",
       "  'right',\n",
       "  'reason',\n",
       "  'airport',\n",
       "  'film',\n",
       "  'see',\n",
       "  'far',\n",
       "  'actually',\n",
       "  'like',\n",
       "  'well',\n",
       "  'favourite',\n",
       "  'plot',\n",
       "  'nice',\n",
       "  'mid',\n",
       "  'air',\n",
       "  'hello',\n",
       "  'jack',\n",
       "  'crash',\n",
       "  'didn',\n",
       "  'oil',\n",
       "  'rig',\n",
       "  'sink',\n",
       "  'maybe',\n",
       "  'maker',\n",
       "  'try',\n",
       "  'cross',\n",
       "  'original',\n",
       "  'airport',\n",
       "  'popular',\n",
       "  'disaster',\n",
       "  'flick',\n",
       "  'period',\n",
       "  'poseidon',\n",
       "  'adventure',\n",
       "  'submerge',\n",
       "  'stay',\n",
       "  'end',\n",
       "  'stark',\n",
       "  'dilemma',\n",
       "  'face',\n",
       "  'trap',\n",
       "  'inside',\n",
       "  'suffocate',\n",
       "  'air',\n",
       "  'run',\n",
       "  'drown',\n",
       "  'flood',\n",
       "  'door',\n",
       "  'open',\n",
       "  'decent',\n",
       "  'idea',\n",
       "  'great',\n",
       "  'little',\n",
       "  'disaster',\n",
       "  'flick',\n",
       "  'but',\n",
       "  'bad',\n",
       "  'unsympathetic',\n",
       "  'character',\n",
       "  'dull',\n",
       "  'dialogue',\n",
       "  'lethargic',\n",
       "  'set',\n",
       "  'piece',\n",
       "  'real',\n",
       "  'lack',\n",
       "  'danger',\n",
       "  'suspense',\n",
       "  'tension',\n",
       "  'mean',\n",
       "  'miss',\n",
       "  'opportunity',\n",
       "  'sluggish',\n",
       "  'plot',\n",
       "  'keep',\n",
       "  'entertain',\n",
       "  'odd',\n",
       "  'minute',\n",
       "  'not',\n",
       "  'much',\n",
       "  'happen',\n",
       "  'plane',\n",
       "  'sink',\n",
       "  'not',\n",
       "  'much',\n",
       "  'urgency',\n",
       "  'think',\n",
       "  'should',\n",
       "  'navy',\n",
       "  'involve',\n",
       "  'thing',\n",
       "  'don',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'much',\n",
       "  'few',\n",
       "  'shot',\n",
       "  'huge',\n",
       "  'ship',\n",
       "  'helicopter',\n",
       "  'fly',\n",
       "  'but',\n",
       "  'lack',\n",
       "  'george',\n",
       "  'kennedy',\n",
       "  'jinx',\n",
       "  'airline',\n",
       "  'worker',\n",
       "  'joe',\n",
       "  'patroni',\n",
       "  'but',\n",
       "  'get',\n",
       "  'couple',\n",
       "  'scene',\n",
       "  'barely',\n",
       "  'say',\n",
       "  'prefer',\n",
       "  'look',\n",
       "  'worry',\n",
       "  'background',\n",
       "  'br',\n",
       "  'br',\n",
       "  'home',\n",
       "  'video',\n",
       "  'theatrical',\n",
       "  'version',\n",
       "  'airport',\n",
       "  'run',\n",
       "  'minute',\n",
       "  'tv',\n",
       "  'version',\n",
       "  'add',\n",
       "  'extra',\n",
       "  'hour',\n",
       "  'footage',\n",
       "  'include',\n",
       "  'new',\n",
       "  'open',\n",
       "  'credit',\n",
       "  'sequence',\n",
       "  'scene',\n",
       "  'george',\n",
       "  'kennedy',\n",
       "  'patroni',\n",
       "  'flashback',\n",
       "  'flesh',\n",
       "  'character',\n",
       "  'long',\n",
       "  'rescue',\n",
       "  'scene',\n",
       "  'discovery',\n",
       "  'couple',\n",
       "  'dead',\n",
       "  'body',\n",
       "  'include',\n",
       "  'navigator',\n",
       "  'like',\n",
       "  'extra',\n",
       "  'footage',\n",
       "  'not',\n",
       "  'sure',\n",
       "  'sit',\n",
       "  'near',\n",
       "  'hour',\n",
       "  'cut',\n",
       "  'airport',\n",
       "  'expect',\n",
       "  'film',\n",
       "  'date',\n",
       "  'badly',\n",
       "  'horrible',\n",
       "  'fashion',\n",
       "  'interior',\n",
       "  'design',\n",
       "  'choice',\n",
       "  'no',\n",
       "  'toy',\n",
       "  'plane',\n",
       "  'model',\n",
       "  'effect',\n",
       "  'aren',\n",
       "  'great',\n",
       "  'airport',\n",
       "  'sequel',\n",
       "  'take',\n",
       "  'pride',\n",
       "  'place',\n",
       "  'razzie',\n",
       "  'award',\n",
       "  'hall',\n",
       "  'shame',\n",
       "  'think',\n",
       "  'lot',\n",
       "  'wrong',\n",
       "  'film',\n",
       "  'reckon',\n",
       "  'little',\n",
       "  'harsh',\n",
       "  'action',\n",
       "  'scene',\n",
       "  'little',\n",
       "  'dull',\n",
       "  'unfortunately',\n",
       "  'pace',\n",
       "  'slow',\n",
       "  'not',\n",
       "  'much',\n",
       "  'excitement',\n",
       "  'tension',\n",
       "  'generate',\n",
       "  'shame',\n",
       "  'reckon',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'film',\n",
       "  'properly',\n",
       "  'br',\n",
       "  'br',\n",
       "  'production',\n",
       "  'value',\n",
       "  'alright',\n",
       "  'nothing',\n",
       "  'spectacular',\n",
       "  'act',\n",
       "  'isn',\n",
       "  'great',\n",
       "  'time',\n",
       "  'oscar',\n",
       "  'winner',\n",
       "  'jack',\n",
       "  'lemmon',\n",
       "  'say',\n",
       "  'mistake',\n",
       "  'star',\n",
       "  'time',\n",
       "  'oscar',\n",
       "  'winner',\n",
       "  'james',\n",
       "  'stewart',\n",
       "  'look',\n",
       "  'old',\n",
       "  'frail',\n",
       "  'time',\n",
       "  'oscar',\n",
       "  'winner',\n",
       "  'lee',\n",
       "  'grant',\n",
       "  'look',\n",
       "  'drink',\n",
       "  'sir',\n",
       "  'christopher',\n",
       "  'lee',\n",
       "  'give',\n",
       "  'little',\n",
       "  'plenty',\n",
       "  'familiar',\n",
       "  'face',\n",
       "  'look',\n",
       "  'too',\n",
       "  'br',\n",
       "  'br',\n",
       "  'airport',\n",
       "  'disaster',\n",
       "  'orientate',\n",
       "  'airport',\n",
       "  'film',\n",
       "  'far',\n",
       "  'like',\n",
       "  'idea',\n",
       "  'bite',\n",
       "  'silly',\n",
       "  'production',\n",
       "  'bland',\n",
       "  'direction',\n",
       "  'doesn',\n",
       "  'help',\n",
       "  'film',\n",
       "  'sink',\n",
       "  'plane',\n",
       "  'shouldn',\n",
       "  'bore',\n",
       "  'lethargic',\n",
       "  'follow',\n",
       "  'concorde',\n",
       "  'airport'],\n",
       " ['brilliant',\n",
       "  'act',\n",
       "  'lesley',\n",
       "  'ann',\n",
       "  'warren',\n",
       "  'well',\n",
       "  'dramatic',\n",
       "  'hobo',\n",
       "  'lady',\n",
       "  'see',\n",
       "  'love',\n",
       "  'scene',\n",
       "  'clothe',\n",
       "  'warehouse',\n",
       "  '2',\n",
       "  'none',\n",
       "  'corn',\n",
       "  'face',\n",
       "  'classic',\n",
       "  'good',\n",
       "  'blaze',\n",
       "  'saddle',\n",
       "  'lawyer',\n",
       "  'superb',\n",
       "  'accuse',\n",
       "  'turncoat',\n",
       "  'sell',\n",
       "  'boss',\n",
       "  'dishonest',\n",
       "  'lawyer',\n",
       "  'pepto',\n",
       "  'bolt',\n",
       "  'shrug',\n",
       "  'indifferently',\n",
       "  'lawyer',\n",
       "  'say',\n",
       "  'funny',\n",
       "  'word',\n",
       "  'jeffrey',\n",
       "  'tambor',\n",
       "  'favorite',\n",
       "  'late',\n",
       "  'larry',\n",
       "  'sander',\n",
       "  'fantastic',\n",
       "  'too',\n",
       "  'mad',\n",
       "  'millionaire',\n",
       "  'want',\n",
       "  'crush',\n",
       "  'ghetto',\n",
       "  'character',\n",
       "  'malevolent',\n",
       "  'usual',\n",
       "  'hospital',\n",
       "  'scene',\n",
       "  'scene',\n",
       "  'homeless',\n",
       "  'invade',\n",
       "  'demolition',\n",
       "  'site',\n",
       "  'time',\n",
       "  'classic',\n",
       "  'look',\n",
       "  'leg',\n",
       "  'scene',\n",
       "  'big',\n",
       "  'digger',\n",
       "  'fight',\n",
       "  'bleed',\n",
       "  'movie',\n",
       "  'get',\n",
       "  'well',\n",
       "  'time']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('decent', 0.7010826468467712),\n",
       " ('alright', 0.6637446284294128),\n",
       " ('great', 0.654833197593689),\n",
       " ('nice', 0.6515093445777893),\n",
       " ('excellent', 0.6245449781417847)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.wv.similar_by_word(word=\"good\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7174395322799683),\n",
       " ('horrible', 0.7109150290489197),\n",
       " ('suck', 0.7039785385131836),\n",
       " ('awful', 0.6831482648849487),\n",
       " ('lousy', 0.6812159419059753)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.wv.similar_by_word(word=\"bad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('would', 0.904498815536499),\n",
       " ('eventy', 0.8563498854637146),\n",
       " ('have', 0.840903639793396),\n",
       " ('-PRON-', 0.7821750640869141),\n",
       " ('s', 0.7486315965652466)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.similar_by_word(word=\"be\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.7174395322799683),\n",
       " ('horrible', 0.7109150290489197),\n",
       " ('suck', 0.7039785385131836),\n",
       " ('awful', 0.6831482648849487),\n",
       " ('lousy', 0.6812159419059753)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.most_similar(positive=  \"bad\",topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5900896"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.similarity(\"good\",\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27340782"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.similarity(\"good\",\"be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Word2Vec.accuracy of <gensim.models.word2vec.Word2Vec object at 0x7f5683f8e208>>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('college', 0.7996352910995483),\n",
       " ('class', 0.7899004220962524),\n",
       " ('student', 0.7800016403198242),\n",
       " ('schooler', 0.7695136070251465),\n",
       " ('teacher', 0.7596186995506287)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.similar_by_word(word=\"school\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('slapstick', 0.7126612663269043),\n",
       " ('satire', 0.7032158374786377),\n",
       " ('farce', 0.6686745882034302),\n",
       " ('parody', 0.6662254333496094),\n",
       " ('humor', 0.659766435623169)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.similar_by_word(word=\"comedy\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('suspense', 0.6356149911880493),\n",
       " ('thrill', 0.6329518556594849),\n",
       " ('pace', 0.5751595497131348),\n",
       " ('choreograph', 0.5640361309051514),\n",
       " ('tense', 0.5584642291069031)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.similar_by_word(word=\"action\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jibin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jibin/.local/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('depress', 0.7577664852142334),\n",
       " ('cry', 0.7323997616767883),\n",
       " ('honest', 0.665052056312561),\n",
       " ('happy', 0.6612464785575867),\n",
       " ('heartwarming', 0.6591799855232239)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.similar_by_word(word=\"sad\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(review):\n",
    "    index_review = []\n",
    "    for word in review:\n",
    "        try:\n",
    "            index_review.append(emb_model.wv.vocab[word].index)\n",
    "        except: \n",
    "             pass\n",
    "    return torch.tensor(index_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1423"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(review) for review in reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'br'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.wv.index2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_value = len(emb_model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lengths = [len(sentence) for sentence in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_review = max(review_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 4, 6]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.utils.rnn.pad_sequence([torch.tensor([1,2,3]), torch.tensor([3,4])], batch_first=True, padding_value=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28166, 100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.FloatTensor(emb_model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28166, 100])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding.from_pretrained(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_review = list(map(lambda review: word2idx(review),reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_review = max([len(review) for review in index_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lengths = [len(sentence) for sentence in index_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_review = torch.nn.utils.rnn.pad_sequence(index_review,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66, 58, 197, 414, 74]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lengths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0 if label == 'negative' else 1 for label in labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(index_review, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.Tensor(y_train)\n",
    "y_val = torch.Tensor(y_val)\n",
    "y_test = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.nn.utils.rnn.pad_sequence(X_train,batch_first=True)\n",
    "X_val = torch.nn.utils.rnn.pad_sequence(X_val,batch_first=True)\n",
    "X_test = torch.nn.utils.rnn.pad_sequence(X_test,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.stack(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(893, 893)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0]),len(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = longest_review\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch[\"text\"]).squeeze(1)\n",
    "        \n",
    "        \n",
    "        loss = criterion(predictions, batch[\"label\"])\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch[\"label\"].cuda())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "# def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "#     epoch_loss = 0\n",
    "#     epoch_acc = 0\n",
    "    \n",
    "#     model.train()\n",
    "    \n",
    "#     for batch in iterator:\n",
    "        \n",
    "#         batch1 = {}\n",
    "        \n",
    "#         batch1[\"text\"] = batch[\"text\"].t().cuda()\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "                \n",
    "#         predictions = model(batch1[\"text\"]).squeeze(1)\n",
    "        \n",
    "# #         print(predictions.shape)\n",
    "# #         print(batch[\"label\"].shape)\n",
    "        \n",
    "#         loss = criterion(predictions, batch[\"label\"].cuda())\n",
    "        \n",
    "#         acc = binary_accuracy(predictions, batch[\"label\"].cuda())\n",
    "        \n",
    "#         loss.backward()\n",
    "        \n",
    "#         optimizer.step()\n",
    "        \n",
    "#         epoch_loss += loss.item()\n",
    "#         epoch_acc += acc.item()\n",
    "        \n",
    "#     return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            \n",
    "            predictions = model(batch[\"text\"]).squeeze(1)\n",
    "          \n",
    "            loss = criterion(predictions, batch[\"label\"])\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch[\"label\"])\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "# def evaluate(model, iterator, criterion):\n",
    "    \n",
    "#     epoch_loss = 0\n",
    "#     epoch_acc = 0\n",
    "    \n",
    "#     model.eval()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "    \n",
    "#         for batch in iterator:\n",
    "#             batch1 = {}\n",
    "#             batch1[\"text\"] = batch[\"text\"].t().cuda()\n",
    "\n",
    "#             predictions = model(batch1[\"text\"]).squeeze(1)\n",
    "          \n",
    "#             loss = criterion(predictions, batch[\"label\"].cuda())\n",
    "            \n",
    "#             acc = binary_accuracy(predictions, batch[\"label\"].cuda())\n",
    "\n",
    "#             epoch_loss += loss.item()\n",
    "#             epoch_acc += acc.item()\n",
    "        \n",
    "#     return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_EPOCHS = 5\n",
    "\n",
    "# for epoch in range(N_EPOCHS):\n",
    "\n",
    "#     train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "#     valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "#     print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  55,  250,   18,  ...,    0,    0,    0],\n",
       "        [   2,  524,  856,  ...,    0,    0,    0],\n",
       "        [ 592,    2,   51,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [  28,  136,  264,  ...,    0,    0,    0],\n",
       "        [ 467,  467,  549,  ...,    0,    0,    0],\n",
       "        [ 501, 2136,  598,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "import numpy as np\n",
    "\n",
    "def iterator_func(X,y):\n",
    "    \n",
    "    size = len(X)\n",
    "    \n",
    "    permutation = np.random.permutation(size)\n",
    "    iterator = []\n",
    "    \n",
    "    for i in range(0,size, batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        \n",
    "        batch = {}\n",
    "        batch['text'] = [X[i] for i in indices]\n",
    "        batch[\"lengths\"] = [len(review) for review in batch[\"text\"]]\n",
    "        batch['label'] = [y[i] for i in indices]\n",
    "        \n",
    "        #sorted\n",
    "        batch[\"text\"],batch[\"label\"] = zip(*sorted(zip(batch[\"text\"],batch[\"label\"]),key=lambda x: len(x[0]),reverse=True))\n",
    "\n",
    "        \n",
    "        batch[\"text\"] = torch.nn.utils.rnn.pad_sequence(batch[\"text\"],batch_first=True,padding_value=padding_value).t().cuda()\n",
    "        batch[\"label\"] = torch.Tensor(batch[\"label\"]).cuda()\n",
    "        \n",
    "        \n",
    "        \n",
    "        iterator.append(batch)\n",
    "    return iterator\n",
    "        \n",
    "train_iterator = iterator_func(X_train,y_train)\n",
    "valid_iterator = iterator_func(X_val,y_val)\n",
    "test_iterator = iterator_func(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "# batch_size = 128 \n",
    "\n",
    "# def iterator_func(X,y):\n",
    "#     permutation = torch.randperm(X.size()[0])\n",
    "#     iterator = []\n",
    "#     for i in range(0,X.size()[0], batch_size):\n",
    "#         indices = permutation[i:i+batch_size]\n",
    "#         batch = {}\n",
    "#         batch['text'] = X[indices]\n",
    "#         batch['label'] = y[indices]\n",
    "#         iterator.append(batch)\n",
    "#     return iterator\n",
    "        \n",
    "# train_iterator = iterator_func(X_train,y_train)\n",
    "# valid_iterator = iterator_func(X_val,y_val)\n",
    "# test_iterator = iterator_func(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(28166, 100)\n",
       "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.631 | Train Acc: 63.48% | Val. Loss: 0.679 | Val. Acc: 60.28% |\n",
      "| Epoch: 02 | Train Loss: 0.473 | Train Acc: 78.33% | Val. Loss: 0.373 | Val. Acc: 83.86% |\n",
      "| Epoch: 03 | Train Loss: 0.398 | Train Acc: 82.40% | Val. Loss: 0.351 | Val. Acc: 85.52% |\n",
      "| Epoch: 04 | Train Loss: 0.369 | Train Acc: 84.11% | Val. Loss: 0.339 | Val. Acc: 85.79% |\n",
      "| Epoch: 05 | Train Loss: 0.350 | Train Acc: 85.09% | Val. Loss: 0.324 | Val. Acc: 86.74% |\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.316 | Test Acc: 86.64% |\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
